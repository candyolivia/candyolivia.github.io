<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Candy Olivia Mawalim | publications</title>
  <meta name="description" content="Personal website of Candy Olivia Mawalim.">

  <!-- Fonts and Icons -->
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons" />

  <!-- CSS Files -->
  <link rel="stylesheet" href="/assets/css/all.min.css">
  <link rel="stylesheet" href="/assets/css/academicons.min.css">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/teaching/">
</head>
<body>
  <!-- Header -->
  <nav id="navbar" class="navbar fixed-top navbar-expand-md grey lighten-5 z-depth-1 navbar-light">
    <div class="container-fluid p-0">
      
        <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Candy Olivia</span> Mawalim</a>
      
      <button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
            </a>
          </li>
          
          <li class="nav-item ">
            <a class="nav-link" href="/profile/">
            Profile
            </a>
          </li>
          
          <li class="nav-item ">
            <a class="nav-link" href="/research/">
            Research
            </a>
          </li>

          <li class="nav-item navbar-active font-weight-bold">
            <a class="nav-link" href="/publications/">
            Publications
            <span class="sr-only">(current)</span>
            </a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" href="/news/">
            News  
            </a>
          </li>
          
          <li class="nav-item ">
            <a class="nav-link" href="/contact/">
              Contact
            </a>
          </li>

        </ul>
      </div>
    </div>
  </nav>

  <!-- Scrolling Progress Bar -->
  <progress id="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>

  <!-- Content -->
  <div class="content">
    
  <h1>Publications</h1>
  <h6><span>*</span> denotes equal contribution and joint lead authorship.</h6>
  
  <h4 class="mt-4">Under Construction</h4>

  <p><br/></p>

  <!-- 2022 -->
  <div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
      <div class="col-sm-1 mt-2 p-0 pr-1">
        <h3 class="bibliography-year">2022</h3>
      </div>
      <div class="col-sm-11 p-0">
        <ol class="bibliography">
          <li>
            <div class="row m-0 mt-3 p-0">
              <div class="col-sm-1 p-0 abbr">
                <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 65px;" href="https://www.elsevier.com/" target="_blank">
                  Elsevier
                </a>
              </div>
              <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
                <div id="stretcu2021c2f" class="col p-0">
                  <h5 class="title mb-0">Speaker Anonymization by Modifying Fundamental Frequency and X-Vectors Singular Value.</h5>
                  <div class="author">
                    <nobr><em>Candy Olivia Mawalim</em>,</nobr> <nobr>Kasorn Galajit,</nobr> <nobr>Jessada Karnjana, </nobr> <nobr>Shunsuke Kidani,</nobr>
                    and
                    <nobr>Masashi Unoki.</nobr>
                  </div>
                  <div>
                    <p class="periodical font-italic">
                        Computer Speech & Language, Elsevier, vol. 73, 101326, 2022.
                    </p>
                  </div>
                  <div class="col p-0">
                    <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                    <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.sciencedirect.com/science/article/pii/S0885230821001194" target="_blank">DOI</a>
                    <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.sciencedirect.com/science/article/pii/S0885230821001194/pdfft?md5=f2a2a2b65c955db3b44e37b04dd49a02&pid=1-s2.0-S0885230821001194-main.pdf" target="_blank">PDF</a>
                    <a class="badge grey waves-effect font-weight-light mr-1" href="https://youtu.be/GZlZFXaIcso" target="_blank">Video</a>
                  </div>
                  <div class="col mt-2 p-0">
                    <div id="stretcu2021c2f-abstract" class="collapse">
                      <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                        Speaker anonymization is a method of protecting voice privacy by concealing individual speaker characteristics while preserving linguistic information. The VoicePrivacy Challenge 2020 was initiated to generalize the task of speaker anonymization. In the challenge, two frameworks for speaker anonymization were introduced; in this study, we propose a method of improving the primary framework by modifying the state-of-the-art speaker individuality feature (namely, x-vector) in a neural waveform speech synthesis model. Our proposed method is constructed based on x-vector singular value modification with a clustering model. We also propose a technique of modifying the fundamental frequency and speech duration to enhance the anonymization performance. To evaluate our method, we carried out objective and subjective tests. The overall objective test results show that our proposed method improves the anonymization performance in terms of the speaker verifiability, whereas the subjective evaluation results show improvement in terms of the speaker dissimilarity. The intelligibility and naturalness of the anonymized speech with speech prosody modification were slightly reduced (less than 5% of word error rate) compared to the results obtained by the baseline system.
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
        </li>
      </ol>
    </div>
  </div>
  <!--  -->

  <!-- 2021 -->
  <div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2021</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography">
        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 65px;" href="https://www.mdpi.com/" target="_blank">
                MDPI
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">Speech Watermarking by McAdams Coefficient Scheme Based on Random Forest Learning.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em>,</nobr>
                  and
                  <nobr>Masashi Unoki.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                    Entropy, MDPI, vol. 23, no. 10, 2021.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://doi.org/10.3390/e23101246" target="_blank">DOI</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.mdpi.com/1099-4300/23/10/1246/pdf?version=1634304903" target="_blank">PDF</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      Speech watermarking has become a promising solution for protecting the security of speech communication systems. We propose a speech watermarking method that uses the McAdams coefficient, which is commonly used for frequency harmonics adjustment. The embedding process was conducted, using bit-inverse shifting. We also developed a random forest classifier, using features related to frequency harmonics for blind detection. An objective evaluation was conducted to analyze the performance of our method in terms of the inaudibility and robustness requirements. The results indicate that our method satisfies the speech watermarking requirements with a 16 bps payload under normal conditions and numerous non-malicious signal processing operations, e.g., conversion to Ogg or MP4 format.
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>   

        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 65px;" href="https://dl.acm.org/journal/tomm" target="_blank">
                TOMM
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">Task-independent Recognition of Communication Skills in Group Interaction Using Time-series Modeling.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em>,</nobr><nobr>Shogo Okada,</nobr>
                  and
                  <nobr>Yukiko I. Nakano.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                    ACM Transactions on Multimedia Computing Communications and Applications, vol. 17, no. 4, pp. 122:1-122:27, 2021.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://doi.org/10.1145/3450283" target="_blank">DOI</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://dl.acm.org/doi/pdf/10.1145/34502831" target="_blank">PDF</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      Case studies of group discussions are considered an effective way to assess communication skills (CS). This method can help researchers evaluate participants’ engagement with each other in a specific realistic context. In this article, multimodal analysis was performed to estimate CS indices using a three-task-type group discussion dataset, the MATRICS corpus. The current research investigated the effectiveness of engaging both static and time-series modeling, especially in task-independent settings. This investigation aimed to understand three main points: first, the effectiveness of time-series modeling compared to nonsequential modeling; second, multimodal analysis in a task-independent setting; and third, important differences to consider when dealing with task-dependent and task-independent settings, specifically in terms of modalities and prediction models. Several modalities were extracted (e.g., acoustics, speaking turns, linguistic-related movement, dialog tags, head motions, and face feature sets) for inferring the CS indices as a regression task. Three predictive models, including support vector regression (SVR), long short-term memory (LSTM), and an enhanced time-series model (an LSTM model with a combination of static and time-series features), were taken into account in this study. Our evaluation was conducted by using the R2 score in a cross-validation scheme. The experimental results suggested that time-series modeling can improve the performance of multimodal analysis significantly in the task-dependent setting (with the best R2 = 0.797 for the total CS index), with word2vec being the most prominent feature. Unfortunately, highly context-related features did not fit well with the task-independent setting. Thus, we propose an enhanced LSTM model for dealing with task-independent settings, and we successfully obtained better performance with the enhanced model than with the conventional SVR and LSTM models (the best R2 = 0.602 for the total CS index). In other words, our study shows that a particular time-series modeling can outperform traditional nonsequential modeling for automatically estimating the CS indices of a participant in a group discussion with regard to task dependency.zation performance in comparison to the secondary baseline system in VP2020.
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>

        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 65px;" href="https://www.apsipa2021.org/" target="_blank">
                APSIPA
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">Improving Security in McAdams Coefficient-Based Speaker Anonymization by Watermarking Method.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em>,</nobr>
                  and
                  <nobr>Masashi Unoki.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                    2021 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Tokyo, Japan, December 2021.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://ieeexplore.ieee.org/document/9689554" target="_blank">IEEE</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9689554&tag=1" target="_blank">PDF</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      Speaker anonymization aims to suppress speaker individuality to protect privacy in speech while preserving the other aspects, such as speech content. One effective solution for anonymization is to modify the McAdams coefficient. In this work, we propose a method to improve the security for speaker anonymization based on the McAdams coefficient by using a speech watermarking approach. The proposed method consists of two main processes: one for embedding and one for detection. In embedding process, two different McAdams coefficients represent binary bits "0" and "1". The watermarked speech is then obtained by frame-by-frame bit inverse switching. Subsequently, the detection process is carried out by a power spectrum comparison. We conducted objective evaluations with reference to the VoicePrivacy 2020 Challenge (VP2020) and of the speech watermarking with reference to the Information Hiding Challenge (IHC) and found that our method could satisfy the blind detection, inaudibility, and robustness requirements in watermarking. It also significantly improved the anonymization performance in comparison to the secondary baseline system in VP2020.
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>
        
      </ol>
    </div>
  </div>
  <!--  -->

</div>

  <!-- Footer -->
  <footer>
    &copy; Copyright 2022 Candy Olivia Mawalim. Powered by <a href="http://jekyllrb.com/" target="_blank"><font color="#a20d0d">Jekyll</font></a> with <a href="https://github.com/alshedivat/al-folio"><font color="#a20d0d">al-folio</font></a> theme. Hosted by <a href="https://pages.github.com/" target="_blank"><font color="#a20d0d">GitHub Pages</font></a>.
  </footer>

  <!-- Core JavaScript Files -->
  <script src="/assets/js/jquery.min.js" type="text/javascript"></script>
  <script src="/assets/js/popper.min.js" type="text/javascript"></script>
  <script src="/assets/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="/assets/js/mdb.min.js" type="text/javascript"></script>
  <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous"></script>
  <script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
  <script src="/assets/js/common.js"></script>

  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    $(document).ready(function() {
      var navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      var progressBar = $('#progress');
      progressBar.css({ 'top': navbarHeight });
      var getMax = function() { return $(document).height() - $(window).height(); }
      var getValue = function() { return $(window).scrollTop(); }   
      // Check if the browser supports the progress element.
      if ('max' in document.createElement('progress')) {
        // Set the 'max' attribute for the first time.
        progressBar.attr({ max: getMax() });
        progressBar.attr({ value: getValue() });
    
        $(document).on('scroll', function() {
          // On scroll only the 'value' attribute needs to be calculated.
          progressBar.attr({ value: getValue() });
        });

        $(window).resize(function() {
          var navbarHeight = $('#navbar').outerHeight(true);
          $('body').css({ 'padding-top': navbarHeight });
          $('progress-container').css({ 'padding-top': navbarHeight });
          progressBar.css({ 'top': navbarHeight });
          // On resize, both the 'max' and 'value' attributes need to be calculated.
          progressBar.attr({ max: getMax(), value: getValue() });
        });
      } else {
        var max = getMax(), value, width;
        var getWidth = function() {
          // Calculate the window width as a percentage.
          value = getValue();
          width = (value/max) * 100;
          width = width + '%';
          return width;
        }
        var setWidth = function() { progressBar.css({ width: getWidth() }); };
        setWidth();
        $(document).on('scroll', setWidth);
        $(window).on('resize', function() {
          // Need to reset the 'max' attribute.
          max = getMax();
          setWidth();
        });
      }
    });
  </script>

  <!-- Code Syntax Highlighting -->
  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
  <script src="/assets/js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- Script Used for Randomizing the Projects Order -->
  <!-- <script type="text/javascript">
    $.fn.shuffleChildren = function() {
      $.each(this.get(), function(index, el) {
        var $el = $(el);
        var $find = $el.children();

        $find.sort(function() {
          return 0.5 - Math.random();
        });

        $el.empty();
        $find.appendTo($el);
      });
    };
    $("#projects").shuffleChildren();
  </script> -->

  <!-- Project Cards Layout -->
  <script type="text/javascript">
    var $grid = $('#projects');

    // $grid.masonry({ percentPosition: true });
    // $grid.masonry('layout');

    // Trigger after images load.
    $grid.imagesLoaded().progress(function() {
      $grid.masonry({ percentPosition: true });
      $grid.masonry('layout');
    });
  </script>

  <!-- Enable Tooltips -->
  <script type="text/javascript">
    $(function () {
      $('[data-toggle="tooltip"]').tooltip()
    })
  </script>

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-54519238-1', 'auto');
    ga('send', 'pageview');
  </script>
</body>
</html>
