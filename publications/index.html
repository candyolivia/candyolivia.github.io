<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Candy Olivia Mawalim | Publications</title>
  <meta name="description" content="Personal website of Candy Olivia Mawalim.">

  <!-- Fonts and Icons -->
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons" />

  <!-- CSS Files -->
  <link rel="stylesheet" href="/assets/css/all.min.css">
  <link rel="stylesheet" href="/assets/css/academicons.min.css">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/teaching/">
</head>
<body>
  <!-- Header -->
  <nav id="navbar" class="navbar fixed-top navbar-expand-md grey lighten-5 z-depth-1 navbar-light">
    <div class="container-fluid p-0">
      
        <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Candy Olivia</span> Mawalim</a>
      
      <button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
            </a>
          </li>
          
          <li class="nav-item ">
            <a class="nav-link" href="/profile/">
            Profile
            </a>
          </li>
          
          <li class="nav-item ">
            <a class="nav-link" href="/research/">
            Research
            </a>
          </li>

          <li class="nav-item navbar-active font-weight-bold">
            <a class="nav-link" href="/publications/">
            Publications
            <span class="sr-only">(current)</span>
            </a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" href="/news/">
            News  
            </a>
          </li>
          
          <li class="nav-item ">
            <a class="nav-link" href="/contact/">
              Contact
            </a>
          </li>

        </ul>
      </div>
    </div>
  </nav>

  <!-- Scrolling Progress Bar -->
  <progress id="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>

  <!-- Content -->
  <div class="content">
    
  <h1>Publications</h1>
  <h6><span>*</span> denotes equal contribution and joint lead authorship.</h6>

  <p><br/></p>

  <!-- 2022 -->
  <div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2022</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography">
        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 70px;" href="https://www.elsevier.com/" target="_blank">
                Elsevier
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">Speaker Anonymization by Modifying Fundamental Frequency and X-Vectors Singular Value.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em>,</nobr> <nobr>Kasorn Galajit,</nobr> <nobr>Jessada Karnjana, </nobr> <nobr>Shunsuke Kidani,</nobr>
                  and
                  <nobr>Masashi Unoki.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                      Computer Speech & Language, Elsevier, vol. 73, 101326, 2022.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.sciencedirect.com/science/article/pii/S0885230821001194" target="_blank">DOI</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.sciencedirect.com/science/article/pii/S0885230821001194/pdfft?md5=f2a2a2b65c955db3b44e37b04dd49a02&pid=1-s2.0-S0885230821001194-main.pdf" target="_blank">PDF</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://youtu.be/GZlZFXaIcso" target="_blank">Video</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      Speaker anonymization is a method of protecting voice privacy by concealing individual speaker characteristics while preserving linguistic information. The VoicePrivacy Challenge 2020 was initiated to generalize the task of speaker anonymization. In the challenge, two frameworks for speaker anonymization were introduced; in this study, we propose a method of improving the primary framework by modifying the state-of-the-art speaker individuality feature (namely, x-vector) in a neural waveform speech synthesis model. Our proposed method is constructed based on x-vector singular value modification with a clustering model. We also propose a technique of modifying the fundamental frequency and speech duration to enhance the anonymization performance. To evaluate our method, we carried out objective and subjective tests. The overall objective test results show that our proposed method improves the anonymization performance in terms of the speaker verifiability, whereas the subjective evaluation results show improvement in terms of the speaker dissimilarity. The intelligibility and naturalness of the anonymized speech with speech prosody modification were slightly reduced (less than 5% of word error rate) compared to the results obtained by the baseline system.
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>
      </ol>
    </div>
  </div>
  <!--  -->

  <!-- 2021 -->
  <div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2021</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography">
        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 70px;" href="https://www.mdpi.com/" target="_blank">
                MDPI
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">Speech Watermarking by McAdams Coefficient Scheme Based on Random Forest Learning.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em>,</nobr>
                  and
                  <nobr>Masashi Unoki.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                    Entropy, MDPI, vol. 23, no. 10, 2021.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://doi.org/10.3390/e23101246" target="_blank">DOI</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.mdpi.com/1099-4300/23/10/1246/pdf?version=1634304903" target="_blank">PDF</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      Speech watermarking has become a promising solution for protecting the security of speech communication systems. We propose a speech watermarking method that uses the McAdams coefficient, which is commonly used for frequency harmonics adjustment. The embedding process was conducted, using bit-inverse shifting. We also developed a random forest classifier, using features related to frequency harmonics for blind detection. An objective evaluation was conducted to analyze the performance of our method in terms of the inaudibility and robustness requirements. The results indicate that our method satisfies the speech watermarking requirements with a 16 bps payload under normal conditions and numerous non-malicious signal processing operations, e.g., conversion to Ogg or MP4 format.
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>   

        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 70px;" href="https://dl.acm.org/journal/tomm" target="_blank">
                TOMM
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">Task-independent Recognition of Communication Skills in Group Interaction Using Time-series Modeling.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em>,</nobr> <nobr>Shogo Okada,</nobr>
                  and
                  <nobr>Yukiko I. Nakano.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                    ACM Transactions on Multimedia Computing Communications and Applications, vol. 17, no. 4, pp. 122:1-122:27, 2021.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://doi.org/10.1145/3450283" target="_blank">DOI</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://dl.acm.org/doi/pdf/10.1145/34502831" target="_blank">PDF</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      Case studies of group discussions are considered an effective way to assess communication skills (CS). This method can help researchers evaluate participants’ engagement with each other in a specific realistic context. In this article, multimodal analysis was performed to estimate CS indices using a three-task-type group discussion dataset, the MATRICS corpus. The current research investigated the effectiveness of engaging both static and time-series modeling, especially in task-independent settings. This investigation aimed to understand three main points: first, the effectiveness of time-series modeling compared to nonsequential modeling; second, multimodal analysis in a task-independent setting; and third, important differences to consider when dealing with task-dependent and task-independent settings, specifically in terms of modalities and prediction models. Several modalities were extracted (e.g., acoustics, speaking turns, linguistic-related movement, dialog tags, head motions, and face feature sets) for inferring the CS indices as a regression task. Three predictive models, including support vector regression (SVR), long short-term memory (LSTM), and an enhanced time-series model (an LSTM model with a combination of static and time-series features), were taken into account in this study. Our evaluation was conducted by using the R2 score in a cross-validation scheme. The experimental results suggested that time-series modeling can improve the performance of multimodal analysis significantly in the task-dependent setting (with the best R2 = 0.797 for the total CS index), with word2vec being the most prominent feature. Unfortunately, highly context-related features did not fit well with the task-independent setting. Thus, we propose an enhanced LSTM model for dealing with task-independent settings, and we successfully obtained better performance with the enhanced model than with the conventional SVR and LSTM models (the best R2 = 0.602 for the total CS index). In other words, our study shows that a particular time-series modeling can outperform traditional nonsequential modeling for automatically estimating the CS indices of a participant in a group discussion with regard to task dependency.zation performance in comparison to the secondary baseline system in VP2020.
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>

        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold primary-color-dark align-middle" style="width: 70px;" href="https://www.apsipa2021.org/" target="_blank">
                APSIPA
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">Improving Security in McAdams Coefficient-Based Speaker Anonymization by Watermarking Method.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em>,</nobr>
                  and
                  <nobr>Masashi Unoki.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                    2021 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Tokyo, Japan, December 2021.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://ieeexplore.ieee.org/document/9689554" target="_blank">IEEE</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9689554&tag=1" target="_blank">PDF</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      Speaker anonymization aims to suppress speaker individuality to protect privacy in speech while preserving the other aspects, such as speech content. One effective solution for anonymization is to modify the McAdams coefficient. In this work, we propose a method to improve the security for speaker anonymization based on the McAdams coefficient by using a speech watermarking approach. The proposed method consists of two main processes: one for embedding and one for detection. In embedding process, two different McAdams coefficients represent binary bits "0" and "1". The watermarked speech is then obtained by frame-by-frame bit inverse switching. Subsequently, the detection process is carried out by a power spectrum comparison. We conducted objective evaluations with reference to the VoicePrivacy 2020 Challenge (VP2020) and of the speech watermarking with reference to the Information Hiding Challenge (IHC) and found that our method could satisfy the blind detection, inaudibility, and robustness requirements in watermarking. It also significantly improved the anonymization performance in comparison to the secondary baseline system in VP2020.
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>

      </ol>
    </div>
  </div>
  <!--  -->

  <!-- 2020 -->
  <div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2020</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography">
        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold primary-color-dark align-middle" style="width: 70px;" href="http://www.apsipa.org/proceedings/2020/APSIPA-ASC-2020.html" target="_blank">
                APSIPA
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">Speech Information Hiding by Modification of LSF Quantization Index in CELP Codec.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em>,</nobr> <nobr>Shengbei Wang,</nobr>
                  and
                  <nobr>Masashi Unoki.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                    2020 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC), Auckland, New Zealand, December 2020.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://ieeexplore.ieee.org/document/9306401" target="_blank">IEEE</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="http://www.apsipa.org/proceedings/2020/pdfs/0001321.pdf" target="_blank">PDF</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      A prospective method for securing digital speech communication is by hiding the information within the speech. Most of the speech information hiding methods proposed in prior research are lacking in robustness when dealing with the encoding process (e.g. the code-excited linear prediction (CELP) codec). The CELP codecs provide a codebook that represents the encoded signal at a lower bit rate. As essential features in speech coding, line spectral frequencies (LSFs) are generally included in the codebook. Consequently, LSFs are considered as a prospective medium for information hiding that is robust against CELP codecs. In this paper, we propose a speech information hiding method that modifies the least significant bit of the LSF quantization obtained by a CELP codec. We investigated the feasibility of our proposed method by objective evaluation in terms of detection accuracy and inaudibility. The evaluation results confirmed the reliability of our proposed method with some further potential improvement (multiple embedding and varying segmentation lengths). The results also showed that our proposed method is robust against several signal processing operations, such as resampling, adding Gaussian noise, and several CELP codecs (i.e., the Federation Standard-1016 CELP, G.711, and G.726).
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>

        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold primary-color-dark align-middle" style="width: 70px;" href="http://www.interspeech2020.org/" target="_blank">
                Interspeech
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">X-Vector Singular Value Modification and Statistical-Based Decomposition with Ensemble Regression Modeling for Speaker Anonymization System.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em>,</nobr> <nobr>Kasorn Galajit,</nobr> <nobr>Jessada Karnjana, </nobr>
                  and
                  <nobr>Masashi Unoki.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                    Interspeech 2020, 21st Annual Conference of the International Speech Communication Association, Virtual Event, Shanghai, China, pp. 1703–1707, October 2020.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.isca-speech.org/archive/interspeech_2020/mawalim20_interspeech.html" target="_blank">DOI</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.isca-speech.org/archive/pdfs/interspeech_2020/mawalim20_interspeech.pdf" target="_blank">PDF</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      Anonymizing speaker individuality is crucial for ensuring voice privacy protection. In this paper, we propose a speaker individuality anonymization system that uses singular value modification and statistical-based decomposition on an x-vector with ensemble regression modeling. An anonymization system requires speaker-to-speaker correspondence (each speaker corresponds to a pseudo-speaker), which may be possible by modifying significant x-vector elements. The significant elements were determined by singular value decomposition and variant analysis. Subsequently, the anonymization process was performed by an ensemble regression model trained using x-vector pools with clustering-based pseudo-targets. The results demonstrated that our proposed anonymization system effectively improves objective verifiability, especially in anonymized trials and anonymized enrollments setting, by preserving similar intelligibility scores with the baseline system introduced in the VoicePrivacy 2020 Challenge.
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>

        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold success-color-dark align-middle" style="width: 70px;" href="https://www.springer.com/series/11156" target="_blank">
                Springer
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">Audio Information Hiding Based on Cochlear Delay Characteristics with Optimized Segment Selection.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em> 
                  and
                  <nobr>Masashi Unoki.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                    Advances in Intelligent Systems and Computing, Springer, vol. 1145, 2020.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://link.springer.com/chapter/10.1007/978-3-030-46828-6_12" target="_blank">DOI</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      Audio information hiding (AIH) based on cochlear delay (CD) characteristics is a promising technique to deal with the trade-off between inaudibility and robustness requirements effectively. However, the use of phase-shift keying (PSK) for blindly detectable AIH based on CD characteristics caused abrupt phase changing (phase spread spectrum), which leads to bad inaudibility. This paper proposed the technique to reduce the spread spectrum from PSK by segment selection process with spline interpolation optimization. Objective evaluation to measure the detection accuracy (BDR) and inaudibility (PEAQ and LSD) was carried out with 102 various genre music clips dataset. Based on the evaluation result, our proposed method could successfully reduce the spread spectrum caused by PSK by having improvement on inaudibility test with adequate detection accuracy up to 1024 bps.
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>
      </ol>
    </div>
  </div>
  <!--  -->

  <!-- 2019 -->
  <div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2019</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography">
        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 70px;" href="http://www.risp.jp/" target="_blank">
                RISP
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">Feasibility of Audio Information Hiding Using Linear Time Variant IIR Filters Based on Cochlear Delay.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em></nobr>
                  and
                  <nobr>Masashi Unoki.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                    Journal of Signal Processing, Research Institute of Signal Processing, vol. 23, no. 4, 2019.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://doi.org/10.2299/jsp.23.155" target="_blank">DOI</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://www.jstage.jst.go.jp/article/jsp/23/4/23_155/_pdf/-char/en" target="_blank">PDF</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      A reported technique for cochlear delay (CD) based audio information hiding achieved imperceptibility in non-blind approaches. However, the phase shift keying (PSK) technique was utilized with a blind method, causing drastically phase changes that imply perceptible information was inserted. This paper presents an investigation on the feasibility of hiding information in the linear time variant (LTV) system. We adapted a CD filter design for the LTV system in the embedding scheme. The detection scheme was conducted using instantaneous chirp-z transformation (CZT). Objective tests for checking the imperceptibility (PEAQ and LSD) and for checking data payload (bit detection rate (BDR)) were conducted to evaluate our method. Our experimental results supported the feasibility of utilizing the CD-based audio information hiding in the LTV system. ln addition, detection regarding both imperceptibility and data payload was better in our method than in the previous blind method.
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>

        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold success-color-dark align-middle" style="width: 70px;" href="https://www.springer.com/gp/computer-science/lncs" target="_blank">
                LNCS
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">Multimodal BigFive Personality Trait Analysis using Communication Skill Indices and Multiple Discussion Types Dataset.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em>, </nobr> <nobr>Shogo Okada, </nobr><nobr>Yukiko I. Nakano, </nobr>
                  and
                  <nobr>Masashi Unoki.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                    Springer LNCS Social Computing and Social Media: Design, Human Behavior, and Analytics, Springer, vol. 11578, 2019.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://link.springer.com/chapter/10.1007/978-3-030-21902-4_27" target="_blank">DOI</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://link.springer.com/content/pdf/10.1007/978-3-030-21902-4_27.pdf" target="_blank">PDF</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      This paper focuses on multimodal analysis in multiple discussion types dataset for estimating BigFive personality traits. The analysis was conducted to achieve two goals: First, clarifying the effectiveness of multimodal features and communication skill indices to predict the BigFive personality traits. Second, identifying the relationship among multimodal features, discussion type, and the BigFive personality traits. The MATRICS corpus, which contains of three discussion task types dataset, was utilized in this experiment. From this corpus, three sets of multimodal features (acoustic, head motion, and linguistic) and communication skill indices were extracted as the input for our binary classification system. The evaluation was conducted by using F1-score in 10-fold cross validation. The experimental results showed that the communication skill indices are important in estimating agreeableness trait. In addition, the scope and freedom of conversation affected the performance of personality traits estimator. The freer a discussion is, the better personality traits estimator can be obtained.
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>
      </ol>
    </div>
  </div>
  <!--  -->

  <!-- 2017 -->
  <div class="row m-0 p-0" style="border-top: 1px solid #ddd; flex-direction: row-reverse;">
    <div class="col-sm-1 mt-2 p-0 pr-1">
      <h3 class="bibliography-year">2017</h3>
    </div>
    <div class="col-sm-11 p-0">
      <ol class="bibliography">
        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold primary-color-dark align-middle" style="width: 70px;" href="https://ieeexplore.ieee.org/xpl/conhome/8306063/proceeding" target="_blank">
                ICEEI
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">POS-based reordering rules for Indonesian-Korean statistical machine translation.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em>, </nobr><nobr>Dessi Puji Lestari, </nobr>
                  and
                  <nobr>Ayu Purwarianti.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                    6th International Conference on Electrical Engineering and Informatics (ICEEI), pp. 1-6, 2017.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://ieeexplore.ieee.org/abstract/document/8312383" target="_blank">IEEE</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      In SMT system, reordering problem is one of the most important and difficult problems to solve. The problem becomes definitely serious due to the different grammatical pattern between source and target language. The previous research about reordering model in SMT use the distortion-based reordering approach. However, this approach is not suitable for Indonesian-Korean translation. The main reason is because the word order between Indonesian and Korean are mostly reversed. Therefore, in this study, we develop a source-side reordering rules by using POS tag and word alignment information. This technique is promising to solve the reordering problem based on the experimental result. By applying 130 reordering rules in ID-KR and 50 reordering rules for KR-ID translation, the quality of translation in term of BLEU score increases 1.25% for ID-KR translation and 0.83% for KR-ID translation. Besides, combining this reordering rules with Korean verb formation rules for ID-KR translation can increase the BLEU score from 38.07 to 49.46 (in 50 simple sentences evaluation).
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>

        <li>
          <div class="row m-0 mt-3 p-0">
            <div class="col-sm-1 p-0 abbr">
              <a class="badge font-weight-bold primary-color-dark align-middle" style="width: 70px;" href="https://aclanthology.org/volumes/Y17-1/" target="_blank">
                PACLIC
              </a>
            </div>
            <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
              <div id="stretcu2021c2f" class="col p-0">
                <h5 class="title mb-0">Rule-based Reordering and Post-Processing for Indonesian-Korean Statistical Machine Translation.</h5>
                <div class="author">
                  <nobr><em>Candy Olivia Mawalim</em>, </nobr><nobr>Dessi Puji Lestari, </nobr>
                  and
                  <nobr>Ayu Purwarianti.</nobr>
                </div>
                <div>
                  <p class="periodical font-italic">
                    In Proceedings of the 31st Pacific Asia Conference on Language, Information and Computation, pages 287–295, Cebu, Phillippines, 2017.
                  </p>
                </div>
                <div class="col p-0">
                  <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#stretcu2021c2f-abstract" role="button" aria-expanded="false" aria-controls="stretcu2021c2f-abstract">Abstract</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/Y17-1039/" target="_blank">ACL</a>
                  <a class="badge grey waves-effect font-weight-light mr-1" href="https://aclanthology.org/Y17-1039.pdf" target="_blank">PDF</a>
                </div>
                <div class="col mt-2 p-0">
                  <div id="stretcu2021c2f-abstract" class="collapse">
                    <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                      In SMT system, reordering problem is one of the most important and difficult problems to solve. The problem becomes definitely serious due to the different grammatical pattern between source and target language. The previous research about reordering model in SMT use the distortion-based reordering approach. However, this approach is not suitable for Indonesian-Korean translation. The main reason is because the word order between Indonesian and Korean are mostly reversed. Therefore, in this study, we develop a source-side reordering rules by using POS tag and word alignment information. This technique is promising to solve the reordering problem based on the experimental result. By applying 130 reordering rules in ID-KR and 50 reordering rules for KR-ID translation, the quality of translation in term of BLEU score increases 1.25% for ID-KR translation and 0.83% for KR-ID translation. Besides, combining this reordering rules with Korean verb formation rules for ID-KR translation can increase the BLEU score from 38.07 to 49.46 (in 50 simple sentences evaluation).
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </li>
      </ol>
    </div>
  </div>
  <!--  -->

</div>

  <!-- Footer -->
  <footer>
    &copy; Copyright 2022 Candy Olivia Mawalim. Powered by <a href="http://jekyllrb.com/" target="_blank"><font color="#a20d0d">Jekyll</font></a> with <a href="https://github.com/alshedivat/al-folio"><font color="#a20d0d">al-folio</font></a> theme. Hosted by <a href="https://pages.github.com/" target="_blank"><font color="#a20d0d">GitHub Pages</font></a>.
  </footer>

  <!-- Core JavaScript Files -->
  <script src="/assets/js/jquery.min.js" type="text/javascript"></script>
  <script src="/assets/js/popper.min.js" type="text/javascript"></script>
  <script src="/assets/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="/assets/js/mdb.min.js" type="text/javascript"></script>
  <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous"></script>
  <script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
  <script src="/assets/js/common.js"></script>

  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    $(document).ready(function() {
      var navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      var progressBar = $('#progress');
      progressBar.css({ 'top': navbarHeight });
      var getMax = function() { return $(document).height() - $(window).height(); }
      var getValue = function() { return $(window).scrollTop(); }   
      // Check if the browser supports the progress element.
      if ('max' in document.createElement('progress')) {
        // Set the 'max' attribute for the first time.
        progressBar.attr({ max: getMax() });
        progressBar.attr({ value: getValue() });
    
        $(document).on('scroll', function() {
          // On scroll only the 'value' attribute needs to be calculated.
          progressBar.attr({ value: getValue() });
        });

        $(window).resize(function() {
          var navbarHeight = $('#navbar').outerHeight(true);
          $('body').css({ 'padding-top': navbarHeight });
          $('progress-container').css({ 'padding-top': navbarHeight });
          progressBar.css({ 'top': navbarHeight });
          // On resize, both the 'max' and 'value' attributes need to be calculated.
          progressBar.attr({ max: getMax(), value: getValue() });
        });
      } else {
        var max = getMax(), value, width;
        var getWidth = function() {
          // Calculate the window width as a percentage.
          value = getValue();
          width = (value/max) * 100;
          width = width + '%';
          return width;
        }
        var setWidth = function() { progressBar.css({ width: getWidth() }); };
        setWidth();
        $(document).on('scroll', setWidth);
        $(window).on('resize', function() {
          // Need to reset the 'max' attribute.
          max = getMax();
          setWidth();
        });
      }
    });
  </script>

  <!-- Code Syntax Highlighting -->
  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
  <script src="/assets/js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- Script Used for Randomizing the Projects Order -->
  <!-- <script type="text/javascript">
    $.fn.shuffleChildren = function() {
      $.each(this.get(), function(index, el) {
        var $el = $(el);
        var $find = $el.children();

        $find.sort(function() {
          return 0.5 - Math.random();
        });

        $el.empty();
        $find.appendTo($el);
      });
    };
    $("#projects").shuffleChildren();
  </script> -->

  <!-- Project Cards Layout -->
  <script type="text/javascript">
    var $grid = $('#projects');

    // $grid.masonry({ percentPosition: true });
    // $grid.masonry('layout');

    // Trigger after images load.
    $grid.imagesLoaded().progress(function() {
      $grid.masonry({ percentPosition: true });
      $grid.masonry('layout');
    });
  </script>

  <!-- Enable Tooltips -->
  <script type="text/javascript">
    $(function () {
      $('[data-toggle="tooltip"]').tooltip()
    })
  </script>

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-54519238-1', 'auto');
    ga('send', 'pageview');
  </script>
</body>
</html>
