<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Candy Olivia Mawalim | Social Signal Processing </title>
  <meta name="description" content="Personal website of Candy Olivia Mawalim.">

  <!-- Fonts and Icons -->
  <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons" />

  <!-- CSS Files -->
  <link rel="stylesheet" href="/assets/css/all.min.css">
  <link rel="stylesheet" href="/assets/css/academicons.min.css">
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/teaching/">
</head>
<body>
  <!-- Header -->
  <nav id="navbar" class="navbar fixed-top navbar-expand-md grey lighten-5 z-depth-1 navbar-light">
    <div class="container-fluid p-0">
      
        <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Candy Olivia</span> Mawalim</a>
      
      <button class="navbar-toggler ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
            </a>
          </li>
          
          <li class="nav-item ">
            <a class="nav-link" href="/profile/">
            Profile
            </a>
          </li>
          
          <li class="nav-item navbar-active font-weight-bold">
            <a class="nav-link" href="/research/">
            Research
            <span class="sr-only">(current)</span>
            </a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" href="/publications/">
            Publications
            </a>
          </li>

          <li class="nav-item ">
            <a class="nav-link" href="/news/">
            News  
            </a>
          </li>
          
          <li class="nav-item ">
            <a class="nav-link" href="/contact/">
              Contact
            </a>
          </li>

        </ul>
      </div>
    </div>
  </nav>

  <!-- Scrolling Progress Bar -->
  <progress id="progress" value="0">
    <div class="progress-container">
      <span class="progress-bar"></span>
    </div>
  </progress>

  <!-- Content -->
  <div class="content">
    
    <h1>Personality Traits and Communication Skills Assessment Modeling</h1>
    
    <p><br /></p>

    <div class="clearfix" align="center">

      <img src="/assets/img/research/ssp/group_discussion.png">
    </div>

    <p><br /></p>

    <div class="text-justify p-0">
      <div class="clearfix" align="justify">

        <p>Interpersonal communication is the process of exchanging information, ideas, and emotions between two or more individuals. Effective interpersonal communication skills are essential in our global and multicultural society, where people from diverse backgrounds interact with each other. Communication skills include verbal and nonverbal cues, active listening, empathy, and emotional intelligence. Without these skills, misunderstandings can occur, leading to conflicts, and limiting productivity in personal and professional relationships. Therefore, it is essential to assess these skills and improve them to ensure successful communication.</p>

        <p>Manual assessment of interpersonal communication skills by experts is usually time-consuming and expensive. Moreover, manual assessment can be subjective, leading to biased results. This research aims to automatically assess the skills by social signal processing (SSP). SSP refers to the process of analyzing and interpreting nonverbal social signals, such as facial expressions, body language, and tone of voice, to understand human behavior and emotions. SSP algorithms use machine learning and computer vision techniques to extract social cues and interpret them to make judgments about human behavior and emotional states.</p>

        <p>SSP has several potential applications, including improving human-human and human-computer interaction. With the use of SSP algorithms, computers can sense, understand, and respond intelligently and naturally to human emotional feedback. This capability enables machines to respond to human emotions, which can improve user experience and engagement. SSP can also enhance human-human communication by improving social awareness, reducing misunderstandings, and enhancing empathy. Therefore, SSP has the potential to revolutionize communication and interaction in our global and multicultural society by enabling better understanding and connection between people of different backgrounds.</p>

      </div>
    </div>

    <p><br /></p>

    <div class="card mt-3 p-3">
      <h3 class="card-title"><b>Related Publications</b></h3>
      <hr>
      <div>
        <ol class="bibliography">

          <li>
            <div class="row m-0 mt-3 p-0">
              <div class="col-sm-1 p-0 abbr">
                <a class="badge font-weight-bold primary-color-dark align-middle" style="width: 75px;" href="https://mum-conf.org/2022/" target="_blank">
                  ACM-MUM
                </a>
              </div>
              <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
                <div id="omkko2022_acmmum" class="col p-0">
                  <h5 class="title mb-0">Multimodal Analysis for Communication Skill and Self-Efficacy Level Estimation in Job Interview Scenario.</h5>
                  <div class="author">
                    <nobr>Tomoya Ohba*,</nobr> <nobr><em>Candy Olivia Mawalim*</em>,</nobr> <nobr>Shun Katada,</nobr> <nobr>Haruki Kuroki,</nobr>
                    and
                    <nobr>Shogo Okada.</nobr>
                  </div>
                  <div>
                    <p class="periodical font-italic">
                      The 21st International Conference on Mobile and Ubiquitous Multimedia (ACM MUM 2022), Lisbon, Portugal, 27--30 November 2022.
                    </p>
                  </div>
                  <div class="col p-0">
                    <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#omkko2022_acmmum-abstract" role="button" aria-expanded="false" aria-controls="omkko2022_acmmum-abstract">Abstract</a>
                    <a class="badge grey waves-effect font-weight-light mr-1" href="https://doi.org/10.1145/3568444.3568461" target="_blank">DOI</a>
                    <a class="badge grey waves-effect font-weight-light mr-1" href="https://dl.acm.org/doi/pdf/10.1145/3568444.3568461" target="_blank">PDF</a>
                  </div>
                  <div class="col mt-2 p-0">
                    <div id="omkko2022_acmmum-abstract" class="collapse">
                      <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                        An interview for a job recruiting process requires applicants to demonstrate their communication skills. Interviewees sometimes become nervous about the interview because interviewees themselves do not know their assessed score. This study investigates the relationship between the communication skill (CS) and the  self-efficacy level (SE) of interviewees through multimodal modeling. We also clarify the difference between effective features in the prediction of CS and SE labels. For this purpose, we collect a novel multimodal job interview data corpus by using a job interview agent system where users experience the interview using a virtual reality head-mounted display (VR-HMD). The data corpus includes annotations of CS by third-party experts and SE annotations by the interviewees. The data corpus also includes various kinds of multimodal data, including audio, biological (i.e., physiological), gaze, and language data. We present two types of regression models, linear regression and sequential-based regression models, to predict CS, SE, and the gap (GA) between skill and self-efficacy. Finally, we report that the model with acoustic, gaze, and linguistic features has the best regression accuracy in CS prediction (correlation coefficient r = 0.637). Furthermore, the regression model with biological features achieves the best accuracy in SE prediction (r = 0.330).
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </li>

          <hr>

          <li>
            <div class="row m-0 mt-3 p-0">
              <div class="col-sm-1 p-0 abbr">
                <a class="badge font-weight-bold danger-color-dark align-middle" style="width: 75px;" href="https://dl.acm.org/journal/tomm" target="_blank">
                  TOMM
                </a>
              </div>
              <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
                <div id="mon2021_tomm" class="col p-0">
                  <h5 class="title mb-0">Task-independent Recognition of Communication Skills in Group Interaction Using Time-series Modeling.</h5>
                  <div class="author">
                    <nobr><em>Candy Olivia Mawalim</em>,</nobr> <nobr>Shogo Okada,</nobr>
                    and
                    <nobr>Yukiko I. Nakano.</nobr>
                  </div>
                  <div>
                    <p class="periodical font-italic">
                      ACM Transactions on Multimedia Computing Communications and Applications, vol. 17, no. 4, pp. 122:1-122:27, 2021.
                    </p>
                  </div>
                  <div class="col p-0">
                    <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#mon2021_tomm-abstract" role="button" aria-expanded="false" aria-controls="mon2021_tomm-abstract">Abstract</a>
                    <a class="badge grey waves-effect font-weight-light mr-1" href="https://doi.org/10.1145/3450283" target="_blank">DOI</a>
                    <a class="badge grey waves-effect font-weight-light mr-1" href="https://dl.acm.org/doi/pdf/10.1145/3450283" target="_blank">PDF</a>
                  </div>
                  <div class="col mt-2 p-0">
                    <div id="mon2021_tomm-abstract" class="collapse">
                      <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                        Case studies of group discussions are considered an effective way to assess communication skills (CS). This method can help researchers evaluate participants’ engagement with each other in a specific realistic context. In this article, multimodal analysis was performed to estimate CS indices using a three-task-type group discussion dataset, the MATRICS corpus. The current research investigated the effectiveness of engaging both static and time-series modeling, especially in task-independent settings. This investigation aimed to understand three main points: first, the effectiveness of time-series modeling compared to nonsequential modeling; second, multimodal analysis in a task-independent setting; and third, important differences to consider when dealing with task-dependent and task-independent settings, specifically in terms of modalities and prediction models. Several modalities were extracted (e.g., acoustics, speaking turns, linguistic-related movement, dialog tags, head motions, and face feature sets) for inferring the CS indices as a regression task. Three predictive models, including support vector regression (SVR), long short-term memory (LSTM), and an enhanced time-series model (an LSTM model with a combination of static and time-series features), were taken into account in this study. Our evaluation was conducted by using the R2 score in a cross-validation scheme. The experimental results suggested that time-series modeling can improve the performance of multimodal analysis significantly in the task-dependent setting (with the best R2 = 0.797 for the total CS index), with word2vec being the most prominent feature. Unfortunately, highly context-related features did not fit well with the task-independent setting. Thus, we propose an enhanced LSTM model for dealing with task-independent settings, and we successfully obtained better performance with the enhanced model than with the conventional SVR and LSTM models (the best R2 = 0.602 for the total CS index). In other words, our study shows that a particular time-series modeling can outperform traditional nonsequential modeling for automatically estimating the CS indices of a participant in a group discussion with regard to task dependency.
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </li>

          <hr>

          <li>
            <div class="row m-0 mt-3 p-0">
              <div class="col-sm-1 p-0 abbr">
                <a class="badge font-weight-bold success-color-dark align-middle" style="width: 75px;" href="https://www.springer.com/gp/computer-science/lncs" target="_blank">
                  LNCS
                </a>
              </div>
              <div class="col-sm-11 mt-2 mt-sm-0 p-0 pl-xs-0 pl-sm-4 pr-xs-0 pr-sm-2">
                <div id="monu2019_lncs" class="col p-0">
                  <h5 class="title mb-0">Multimodal BigFive Personality Trait Analysis using Communication Skill Indices and Multiple Discussion Types Dataset.</h5>
                  <div class="author">
                    <nobr><em>Candy Olivia Mawalim</em>, </nobr> <nobr>Shogo Okada, </nobr><nobr>Yukiko I. Nakano, </nobr>
                    and
                    <nobr>Masashi Unoki.</nobr>
                  </div>
                  <div>
                    <p class="periodical font-italic">
                      Springer LNCS Social Computing and Social Media: Design, Human Behavior, and Analytics, Springer, vol. 11578, 2019.
                    </p>
                  </div>
                  <div class="col p-0">
                    <a class="badge grey waves-effect font-weight-light mr-1" data-toggle="collapse" href="#monu2019_lncs-abstract" role="button" aria-expanded="false" aria-controls="monu2019_lncs-abstract">Abstract</a>
                    <a class="badge grey waves-effect font-weight-light mr-1" href="https://link.springer.com/chapter/10.1007/978-3-030-21902-4_27" target="_blank">DOI</a>
                    <a class="badge grey waves-effect font-weight-light mr-1" href="https://link.springer.com/content/pdf/10.1007/978-3-030-21902-4_27.pdf" target="_blank">PDF</a>
                  </div>
                  <div class="col mt-2 p-0">
                    <div id="monu2019_lncs-abstract" class="collapse">
                      <div class="abstract card card-body font-weight-light mr-0 mr-sm-3 p-3">
                        This paper focuses on multimodal analysis in multiple discussion types dataset for estimating BigFive personality traits. The analysis was conducted to achieve two goals: First, clarifying the effectiveness of multimodal features and communication skill indices to predict the BigFive personality traits. Second, identifying the relationship among multimodal features, discussion type, and the BigFive personality traits. The MATRICS corpus, which contains of three discussion task types dataset, was utilized in this experiment. From this corpus, three sets of multimodal features (acoustic, head motion, and linguistic) and communication skill indices were extracted as the input for our binary classification system. The evaluation was conducted by using F1-score in 10-fold cross validation. The experimental results showed that the communication skill indices are important in estimating agreeableness trait. In addition, the scope and freedom of conversation affected the performance of personality traits estimator. The freer a discussion is, the better personality traits estimator can be obtained.
                      </div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </li>
        </ol>
      </div>
    </div>

    <p><br /></p>
  
  </div>

</div>

  <!-- Footer -->
  <footer>
    &copy; Copyright 2022 Candy Olivia Mawalim. Powered by <a href="http://jekyllrb.com/" target="_blank"><font color="#a20d0d">Jekyll</font></a> with <a href="https://github.com/alshedivat/al-folio"><font color="#a20d0d">al-folio</font></a> theme. Hosted by <a href="https://pages.github.com/" target="_blank"><font color="#a20d0d">GitHub Pages</font></a>.
  </footer>

  <!-- Core JavaScript Files -->
  <script src="/assets/js/jquery.min.js" type="text/javascript"></script>
  <script src="/assets/js/popper.min.js" type="text/javascript"></script>
  <script src="/assets/js/bootstrap.min.js" type="text/javascript"></script>
  <script src="/assets/js/mdb.min.js" type="text/javascript"></script>
  <script async="" src="https://cdnjs.cloudflare.com/ajax/libs/masonry/4.2.2/masonry.pkgd.min.js" integrity="sha384-GNFwBvfVxBkLMJpYMOABq3c+d3KnQxudP/mGPkzpZSTYykLBNsZEnG2D9G/X/+7D" crossorigin="anonymous"></script>
  <script src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
  <script src="/assets/js/common.js"></script>

  <!-- Scrolling Progress Bar -->
  <script type="text/javascript">
    $(document).ready(function() {
      var navbarHeight = $('#navbar').outerHeight(true);
      $('body').css({ 'padding-top': navbarHeight });
      $('progress-container').css({ 'padding-top': navbarHeight });
      var progressBar = $('#progress');
      progressBar.css({ 'top': navbarHeight });
      var getMax = function() { return $(document).height() - $(window).height(); }
      var getValue = function() { return $(window).scrollTop(); }   
      // Check if the browser supports the progress element.
      if ('max' in document.createElement('progress')) {
        // Set the 'max' attribute for the first time.
        progressBar.attr({ max: getMax() });
        progressBar.attr({ value: getValue() });
    
        $(document).on('scroll', function() {
          // On scroll only the 'value' attribute needs to be calculated.
          progressBar.attr({ value: getValue() });
        });

        $(window).resize(function() {
          var navbarHeight = $('#navbar').outerHeight(true);
          $('body').css({ 'padding-top': navbarHeight });
          $('progress-container').css({ 'padding-top': navbarHeight });
          progressBar.css({ 'top': navbarHeight });
          // On resize, both the 'max' and 'value' attributes need to be calculated.
          progressBar.attr({ max: getMax(), value: getValue() });
        });
      } else {
        var max = getMax(), value, width;
        var getWidth = function() {
          // Calculate the window width as a percentage.
          value = getValue();
          width = (value/max) * 100;
          width = width + '%';
          return width;
        }
        var setWidth = function() { progressBar.css({ width: getWidth() }); };
        setWidth();
        $(document).on('scroll', setWidth);
        $(window).on('resize', function() {
          // Need to reset the 'max' attribute.
          max = getMax();
          setWidth();
        });
      }
    });
  </script>

  <!-- Code Syntax Highlighting -->
  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet">
  <script src="/assets/js/highlight.pack.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>

  <!-- Script Used for Randomizing the Projects Order -->
  <!-- <script type="text/javascript">
    $.fn.shuffleChildren = function() {
      $.each(this.get(), function(index, el) {
        var $el = $(el);
        var $find = $el.children();

        $find.sort(function() {
          return 0.5 - Math.random();
        });

        $el.empty();
        $find.appendTo($el);
      });
    };
    $("#projects").shuffleChildren();
  </script> -->

  <!-- Project Cards Layout -->
  <script type="text/javascript">
    var $grid = $('#projects');

    // $grid.masonry({ percentPosition: true });
    // $grid.masonry('layout');

    // Trigger after images load.
    $grid.imagesLoaded().progress(function() {
      $grid.masonry({ percentPosition: true });
      $grid.masonry('layout');
    });
  </script>

  <!-- Enable Tooltips -->
  <script type="text/javascript">
    $(function () {
      $('[data-toggle="tooltip"]').tooltip()
    })
  </script>

  <!-- Google Analytics -->
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-54519238-1', 'auto');
    ga('send', 'pageview');
  </script>
</body>
</html>
